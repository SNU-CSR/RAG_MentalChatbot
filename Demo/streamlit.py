<<<<<<< HEAD
import streamlit as st
import google.generativeai as genai

st.title("Mental chat bot")

@st.cache_resource
def load_model():
    model = genai.GenerativeModel('gemini-pro')
    print("model loaded...")
    return model

model = load_model()

# session_state : ê°ì²´ í™œìš©í•´ ëŒ€í™” ì´ë ¥ì„ ì„¸ì…˜ìœ¼ë¡œ ê´€ë¦¬
# ì‚¬ìš©ìžì™€ aiì˜ ë©”ì‹œì§€ ìƒì„±ë  ë•Œë§ˆë‹¤ ëŒ€í™” ì´ë ¥ì— ë©”ì‹œì§€ ì •ë³´ ì¶”ê°€
if "chat_session" not in st.session_state:
    st.session_state["chat_session"] = model.start_chat(history=[])
    
# ëŒ€í™” ì´ë ¥ì— ì¶”ê°€ëœ ë©”ì‹œì§€ëŠ” ì‚¬ìš©ìž ì¸í„°ëž™ì…˜ ìžˆì„ë•Œë§ˆë‹¤
# for loopìœ¼ë¡œ ë©”ì‹œì§€ ì „ì²´ê°€ í™”ë©´ìœ¼ë¡œ ì¶œë ¥ë˜ë„ë¡ í•¨ 
for content in st.session_state.chat_session.history:
    with st.chat_message("ai" if content.role == "model" else "user"):
        st.markdown(content.parts[0].text)
    
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ìž…ë ¥í•˜ì„¸ìš”. "):
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("ai"):
        response = st.session_state.chat_session.send_message(prompt)
        st.markdown(response.text)       
=======
import sys
import os

# í˜„ìž¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ì–»ê³  ë¶€ëª¨ ë””ë ‰í† ë¦¬ë¥¼ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))
sys.path.append(parent_dir)

import streamlit as st
from IntegrationChat import chatbot_response

# Streamlit ì„¤ì •
st.header("ðŸ¤– Mental Health Chatbot")

user_input = st.text_input("ë‹¹ì‹ ì˜ ì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”:")

if st.button("ì „ì†¡"):
    response = chatbot_response(user_input)
    st.write("ì±—ë´‡ì˜ ì‘ë‹µ:")
    st.write(response)
>>>>>>> origin/develop
